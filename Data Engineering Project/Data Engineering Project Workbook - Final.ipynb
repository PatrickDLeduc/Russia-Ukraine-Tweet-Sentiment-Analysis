{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import datetime\n",
    "import nltk\n",
    "import pycld2 as cld2\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from  sklearn.metrics import fowlkes_mallows_score\n",
    "\n",
    "\n",
    "\n",
    "nltk.download([\"names\",\"stopwords\",\"state_union\",\"twitter_samples\",\"movie_reviews\",\"averaged_perceptron_tagger\",\"vader_lexicon\",\"punkt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY\n",
    "consumer_key = 'y8oMppAVPw9DpK3juBkTZoDvs'\n",
    "\n",
    "# API SECRET\n",
    "consumer_secret =  'tIWtYPtu6UhSpCeZcjeerWEk7jrPI0O9ks9YijRu5x4lN6kWPl'\n",
    "\n",
    "# BEARER TOKEN\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAJykaQEAAAAAUng82dZX%2BsucZhLqh6EqRDQPnVw%3DCghiwIoSP4dX3xZzcJJofXtwKwVvhWO45fffJOmd13z4aqPLow'\n",
    "\n",
    "callback_uri = 'oob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret, callback=callback_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_url = auth.get_authorization_url()\n",
    "print(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pin = '9932719'\n",
    "auth.get_access_token(user_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_user(screen_name='code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_json = api.search_30_day('dev', query='Ukraine lang:en (place_country:US OR place_country:CA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15235831",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_json_db =  [json.dumps(t._json) for t in tweets_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the tweet's JSON info and turns it into a dataframe for cleaning\n",
    "tweets_df = pd.concat(pd.json_normalize(tweets_json[i]._json) for i, t in enumerate(tweets_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_df(tweet_json):\n",
    "    \"\"\"\n",
    "    returns dataframe of tweets from list of JSON files\n",
    "    \"\"\"\n",
    "    return pd.concat(pd.json_normalize(tweet_json[i]._json) for i, t in enumerate(tweet_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data as .csv file for easier sharing\n",
    "tweets_df.to_csv('tweets_df_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at all 187 column names\n",
    "for c in tweets_df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['created_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f837121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to build a query\n",
    "# https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/guides/build-standard-query\n",
    "tweets2 = api.search_30_day('dev', query='Ukraine OR Putin OR Zelensky OR Russia lang:en (place_country:CA)', fromDate='202202210000', toDate='202202280000', maxResults=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c84bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = tweet_to_df(tweets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464dc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorry for the ugly code, but it works\n",
    "day = [21, 22, 23, 24, 25, 26, 27, 28, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "day = [str(i) for i in day]\n",
    "hour = ['00', '06', '12', '18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad650c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for d in day:\n",
    "    for h in hour:\n",
    "        data.append(api.search_30_day('dev', query='Ukraine OR Putin OR Zelensky OR Russia lang:en (place_country:CA)', toDate=f'202202{d}{h}00', maxResults=10))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf37e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame()\n",
    "test = [tweet_to_df(data[i]) for i in range(len(data))]\n",
    "for t in test:\n",
    "    new_data = pd.concat([new_data, t])\n",
    "    \n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "feb28_midnight = api.search_30_day('dev', query='Ukraine OR Putin OR Zelensky OR Russia lang:en (place_country:CA)', toDate=f'202202280000', maxResults=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cdcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8398407",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data = []\n",
    "\n",
    "for d in day:\n",
    "    for h in hour:\n",
    "        march_data.append(api.search_30_day('dev', query='Ukraine OR Putin OR Zelensky OR Russia lang:en (place_country:CA)', toDate=f'202203{d}{h}00', maxResults=100))\n",
    "march_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = [tweet_to_df(march_data[i]) for i in range(len(march_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd43bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_tweets = pd.DataFrame()\n",
    "for i in range(len(test2)):\n",
    "    march_tweets = pd.concat([march_tweets, test2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_tweets.to_csv('march01_march08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tweet_dfs(tweet_data):\n",
    "    \"\"\"\n",
    "    Returns dataframe of concatenated tweet dataframes\n",
    "    \"\"\"\n",
    "    tweet_dfs = [tweet_to_df(tweet_data[i]) for i in range(len(tweet_data))]\n",
    "    output_df = pd.DataFrame()\n",
    "    for i in range(len(tweet_dfs)):\n",
    "        output_df = pd.concat([output_df, tweet_dfs[i]])\n",
    "        \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2462e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data_09_on = []\n",
    "\n",
    "day = ['09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n",
    "\n",
    "for d in day:\n",
    "    for h in hour:\n",
    "        march_data_09_on.append(api.search_30_day('dev', query='Ukraine OR Putin OR Zelensky OR Russia lang:en (place_country:CA)', toDate=f'202203{d}{h}00', maxResults=100))\n",
    "march_data_09_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to help me know when I can call on the API again\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data_09_onwards_df = combine_tweet_dfs(march_data_09_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data_09_onwards_df.to_csv('march09_march16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1421688",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(march_data_09_onwards_df.columns) - set(tweets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data_16_on = []\n",
    "\n",
    "day = ['16', '17', '18', '19', '20']\n",
    "\n",
    "for d in day:\n",
    "    for h in hour:\n",
    "        march_data_16_on.append(api.search_30_day('dev', query='Ukraine OR Putin OR Zelensky OR Russia lang:en (place_country:CA)', toDate=f'202203{d}{h}00', maxResults=100))\n",
    "march_data_16_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aaa883",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data_16_onwards_df = combine_tweet_dfs(march_data_16_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_data_16_onwards_df.to_csv('march16_march20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('march01_march08.csv')\n",
    "df2 = pd.read_csv('march09_march16.csv')\n",
    "df3 = pd.read_csv('march16_march20.csv')\n",
    "full_df = pd.concat([df1, df2, df3])\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in  full_df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45226167",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = []\n",
    "\n",
    "for c in full_df.columns:\n",
    "    if c.startswith(('user', 'retweeted_status', 'quoted_status')):\n",
    "        continue\n",
    "    else:\n",
    "        keep.append(c)\n",
    "keep\n",
    "keep = keep[1:]\n",
    "full_df_new = full_df[keep]\n",
    "full_df_new.isna().all()\n",
    "full_df_new.drop(columns=['geo', 'coordinates', 'place', 'contributors'], axis=1, inplace=True)\n",
    "full_df_new.reset_index(drop=True, inplace=True)\n",
    "full_df_new.to_csv('Ukraine_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Ukraine_tweets.csv\")\n",
    "df = df1\n",
    "def decode_uni(string):\n",
    "    string = string.split()\n",
    "    stringdecoded = \"\"\n",
    "    for word in string:\n",
    "        if \"https\" in word:\n",
    "            tempstring = word\n",
    "        else:\n",
    "            word = word.encode(\"ascii\", \"ignore\")\n",
    "            word = str(word.decode())\n",
    "            tempstring = \"\"\n",
    "            for character in word:\n",
    "                if str(character).isalnum() or (\".\" in str(character)) or (\",\" in str(character)) or (\"(\" in str(character)) or (\")\" in str(character)) or (\":\" in str(character)):\n",
    "                    tempstring = tempstring+(str(character))\n",
    "        stringdecoded = stringdecoded+ tempstring + \" \"\n",
    "        temp = stringdecoded.split()\n",
    "        stringdecoded = \"\"\n",
    "        for i in range(len(temp)):\n",
    "            stringdecoded = stringdecoded+temp[i]+\" \"\n",
    "    return stringdecoded\n",
    "#df = df.applymap(decode_uni)\n",
    "#print(df.head())\n",
    "df['text'] = pd.DataFrame(df['text']).applymap(decode_uni)\n",
    "df = df.dropna(axis = 1)\n",
    "df = df.drop('Unnamed: 0', axis = 1)\n",
    "df = df.drop('quote_count', axis = 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f20139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_polarity(topics,tweets):\n",
    "    \"\"\"Returns two lists, one with negative polarity tweets and one \n",
    "    with positive polarity tweets\"\"\"\n",
    "\n",
    "    dfpos = pd.DataFrame()\n",
    "    dfneg = pd.DataFrame()\n",
    "    dfneu = pd.DataFrame()\n",
    "    indexpos = -1\n",
    "    indexneg = -1\n",
    "    indexneu = -1\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # Initialize first look at tweet\n",
    "        first = True\n",
    "        ind = 1\n",
    "        for topic in topics:\n",
    "            # Checks if topic mentioned in tweet\n",
    "            if topic in tweet or topic.upper() in tweet or topic.lower() in tweet \\\n",
    "            or \"#\"+topic in tweet or \"#\"+topic.upper() in tweet or \"#\"+topic.lower() in tweet:\n",
    "                # First time looking at tweet, add first topic id and polarity scores\n",
    "                # Positive polarity\n",
    "                if (sia.polarity_scores(tweet)['compound'] > 0):\n",
    "                    if (first == True):\n",
    "                        pos = {'tweet': tweet, 'topic_'+str(ind): topic, \n",
    "                        'compound_score': sia.polarity_scores(tweet)['compound'], \n",
    "                        'positive_score':sia.polarity_scores(tweet)['pos'], \n",
    "                        'negative_score': sia.polarity_scores(tweet)['neg'],'topic_2':'',\n",
    "                        'topic_3':'','topic_4':'','topic_5':'','topic_6':'','topic_7':''}\n",
    "                        dfpos = dfpos.append(pos, ignore_index = True)\n",
    "                        first = False\n",
    "                        ind = ind+1\n",
    "                        indexpos+=1\n",
    "                    else:\n",
    "                        dfpos.at[indexpos, 'topic_'+str(ind)] = topic\n",
    "                        ind = ind+1\n",
    "                    # If not first pass, only add new topics to 'topic' column\n",
    "                    # Negative polarity\n",
    "                elif(sia.polarity_scores(tweet)==0):\n",
    "                    if (first == True):\n",
    "                        neu = {'tweet': tweet, 'topic_'+str(ind): topic, \n",
    "                        'compound_score': sia.polarity_scores(tweet)['compound'], \n",
    "                        'positive_score':sia.polarity_scores(tweet)['pos'], \n",
    "                        'negative_score': sia.polarity_scores(tweet)['neg'],'topic_2':'',\n",
    "                        'topic_3':'','topic_4':'','topic_5':'','topic_6':'','topic_7':''}\n",
    "                        dfneu = dfneu.append(neg, ignore_index = True)\n",
    "                        first = False\n",
    "                        ind = ind+1\n",
    "                        indexneu+=1\n",
    "                    else:\n",
    "                        dfneu.at[indexneg, 'topic_'+str(ind)] = topic\n",
    "                        ind = ind+1\n",
    "                else:\n",
    "                    if (first == True):\n",
    "                        neg = {'tweet': tweet, 'topic_'+str(ind): topic, \n",
    "                        'compound_score': sia.polarity_scores(tweet)['compound'], \n",
    "                        'positive_score':sia.polarity_scores(tweet)['pos'], \n",
    "                        'negative_score': sia.polarity_scores(tweet)['neg'],'topic_2':'',\n",
    "                        'topic_3':'','topic_4':'','topic_5':'','topic_6':'','topic_7':''}\n",
    "                        dfneg = dfneg.append(neg, ignore_index = True)\n",
    "                        first = False\n",
    "                        ind = ind+1\n",
    "                        indexneg+=1\n",
    "                    else:\n",
    "                        dfneg.at[indexneg, 'topic_'+str(ind)] = topic\n",
    "                        ind = ind+1\n",
    "                    \n",
    "    # If not first pass, only add new topics to 'topic' column\n",
    "    # Indicates first pass is over\n",
    "    return dfpos, dfneg, dfneu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ae6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['Putin','Ukraine','Ukrainian','NATO','Kyiv','Kiev','Zelensky','SWIFT','Russian',\n",
    "          'Russia','UkraineRussianWar','StandWithUkraineÔ∏è']\n",
    "topics = topics.sort()\n",
    "\n",
    "df_pos = pd.DataFrame()\n",
    "df_neg = pd.DataFrame()\n",
    "df_neu = pd.DataFrame()\n",
    "\n",
    "pos, neg, neu = find_polarity(topics,tweets)\n",
    "df_pos = pd.concat([df_pos, pos])\n",
    "df_neg = pd.concat([df_neg, neg])\n",
    "df_neu = pd.concat([df_neu, neu])\n",
    "df_pos['sentiment'] = 1\n",
    "df_neg['sentiment'] = -1\n",
    "df_neu['sentiment'] = 0\n",
    "fulldf = pd.concat([df_pos, df_neg, df_neu])\n",
    "fulldf.to_csv(\"fulldf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks for and returns only english tweets\n",
    "\n",
    "df = pd.read_csv('fulldf.csv')\n",
    "alltweets = df['tweet']\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "lang = []\n",
    "\n",
    "for tweet in alltweets:\n",
    "    lang.append(cld2.detect(tweet)[2][0][1])\n",
    "\n",
    "df['lang'] = lang\n",
    "\n",
    "df = df.loc[df['lang']=='en']\n",
    "\n",
    "df.to_csv('TweetsByTopic_EN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c88f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('TweetsByTopic_EN.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data['topic_1'].replace('Ukrainian', 'Ukraine', inplace=True)\n",
    "data['topic_1'].replace('Russian', 'Russia', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(str.lower)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "tt = TweetTokenizer()\n",
    "tokens = data['tweet'].apply(tt.tokenize)\n",
    "\n",
    "def remove_stopwords(lst):\n",
    "    return ' '.join(word for word in lst if word not in stopwords)\n",
    "\n",
    "new_X = tokens.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replaceDict = dict({\n",
    "'{':\" \", '}':\" \", ',':\"\", '.':\" \", '!':\" \", '\\\\':\" \", '/':\" \", '$':\" \", '%':\" \",\n",
    "'^':\" \", '?':\" \", '\\'':\" \", '\"':\" \", '(':\" \", ')':\" \", '*':\" \", '+':\" \", '-':\" \",\n",
    "'=':\" \", ':':\" \", ';':\" \", ']':\" \", '[':\" \", '`':\" \", '~':\" \",\n",
    "})\n",
    "\n",
    "rep = dict((re.escape(k),v) for k, v in replaceDict.items())\n",
    "pattern = re.compile('|'.join(rep.keys()))\n",
    "def replacer(text):\n",
    "    return rep[re.escape(text.group(0))]\n",
    "\n",
    "words = data.tweet.str.replace(pattern, replacer).str.lower().str.split()\n",
    "# words = pd.DataFrame(words.tolist())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "# stemmed_words = [ps.stem(w) for lst in words for w in lst]\n",
    "def get_stems(lst):\n",
    "    return ' '.join(ps.stem(w) for w in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = words.apply(get_stems)\n",
    "data['stemmed_text'] = stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "X = stemmed_words\n",
    "y = data['topic_1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train) #fit_transform CountVectorizer on training data\n",
    "X_train = tf.fit_transform(X_train)         #fit_transform TfidfTransformer on training data\n",
    "\n",
    "X_test = vectorizer.transform(X_test)       #transform CountVectorizer on testing data\n",
    "X_test = tf.transform(X_test)               #transform TfidfTransformer on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, 11):\n",
    "     km = MiniBatchKMeans(\n",
    "         n_clusters=k,\n",
    "         init=\"k-means++\",\n",
    "         n_init=1,\n",
    "         init_size=1000,\n",
    "         batch_size=1000,\n",
    "     )\n",
    "    \n",
    "    km.fit(X_train)\n",
    "    preds = km.predict(X_test)\n",
    "    print(pd.crosstab(y_test, preds))\n",
    "    print(k, sklearn.metrics.fowlkes_mallows_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = MiniBatchKMeans(\n",
    "        n_clusters=3,\n",
    "        init=\"k-means++\",\n",
    "        n_init=1,\n",
    "        init_size=1000,\n",
    "        batch_size=1000,\n",
    "        random_state=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c578800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(X_train)\n",
    "preds = km.predict(X_test)\n",
    "pd.crosstab(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40845396",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_war = {2:\"Russia\", 0:\"Putin\", 1:\"Ukraine\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817dfb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = pd.Series(preds).map(map_war)\n",
    "# predicted_test\n",
    "sklearn.metrics.accuracy_score(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.fowlkes_mallows_score(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ae262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    " \n",
    "tsvd = TruncatedSVD(2) # we need 2 principal components to use a scatterplot\n",
    "converted_data_train = tsvd.fit_transform(X_train)\n",
    "converted_data_test = tsvd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [i for i in km.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize = (10,6))\n",
    "c_map = plt.cm.get_cmap('jet', 3)\n",
    "plt.scatter(converted_data_test[:, 0], converted_data_test[:, 1], s = 15,\n",
    "            cmap = c_map, c = preds)\n",
    "plt.colorbar()\n",
    "plt.xlabel('PC-1') , plt.ylabel('PC-2')\n",
    "plt.title('Clustering Tweets (K=3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the whole dataframe, but unused in project\n",
    "X = stemmed_words\n",
    "y = data['topic_1']\n",
    "\n",
    "X2 = vectorizer.fit_transform(X)\n",
    "X2 = tf.fit_transform(X2)\n",
    "\n",
    "km.fit(X2)\n",
    "preds = km.predict(X2)\n",
    "# pd.crosstab(y, preds)\n",
    "sklearn.metrics.fowlkes_mallows_score(y, preds)\n",
    "#looking at tweets by cluster\n",
    "data['preds'] = preds\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f547af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cluster0 = data[data['preds'] == 0].sample(100)\n",
    "for t in sample_cluster0['tweet']:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cluster1 = data[data['preds'] == 1].sample(100)\n",
    "for t in sample_cluster1['tweet']:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cluster2 = data[data['preds'] == 2].sample(100)\n",
    "for t in sample_cluster2['tweet']:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa2035",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "tsvd = TruncatedSVD(3) # we need 2 principal components to use a scatterplot\n",
    "converted_data_train = tsvd.fit_transform(X_train)\n",
    "converted_data_test = tsvd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Scatterplot\n",
    "data['keyword'] = data.topic_1.map({'Ukraine': 1, 'Rusia': 2, 'Zelensky': 3, 'Putin':4}).fillna(0).astype(int)\n",
    "x=data.positive_score\n",
    "y=data.negative_score\n",
    "z=data.compound_score\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "c_map = plt.cm.get_cmap('jet', 10)\n",
    "ax.scatter(x, y, z, s = 25,\n",
    "            cmap = c_map, c = data['keyword'], label = {0:\"Ukraine\", 1:\"Russia\", 2:\"Russian\", 3:\"Putin\"})\n",
    "ax.set_xlabel('Positive') , ax.set_ylabel('Negative'), ax.set_zlabel('Compound')\n",
    "plt.title('Scatterplot')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('3DScatter.png',dpi=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61dde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Clustering\n",
    "x=converted_data_test[:, 0]\n",
    "y=converted_data_test[:, 1]\n",
    "z=converted_data_test[:,2]\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "c_map = plt.cm.get_cmap('jet', 10)\n",
    "ax.scatter(x, y, z, s = 25,\n",
    "            cmap = c_map, c = data['keyword'], label = {0:\"Ukraine\", 1:\"Russia\", 2:\"Russian\", 3:\"Putin\"})\n",
    "ax.set_xlabel('PC-1') , ax.set_ylabel('PC-2'), ax.set_zlabel('PC-3')\n",
    "plt.title('Clustering Tweets (K=4)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('3DCluster.png',dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
